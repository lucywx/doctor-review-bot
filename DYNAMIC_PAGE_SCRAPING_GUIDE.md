# åŠ¨æ€é¡µé¢çˆ¬å–æŠ€æœ¯æŒ‡å—

## é—®é¢˜ï¼šå¦‚ä½•æœç´¢åŠ¨æ€é¡µé¢ï¼ˆä¾‹å¦‚ Facebook è¯„è®ºï¼‰ï¼Ÿ

åŠ¨æ€é¡µé¢çš„å†…å®¹é€šè¿‡ JavaScript åŠ è½½ï¼Œæ™®é€š HTTP è¯·æ±‚æ— æ³•è·å–ã€‚

---

## æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | éš¾åº¦ | æˆæœ¬ | å¯é æ€§ | é€‚ç”¨åœºæ™¯ |
|------|------|------|--------|---------|
| **Playwright/Selenium** | ğŸŸ¡ ä¸­ç­‰ | ğŸ’° ä¸­ç­‰ | â­â­â­â­ | é€šç”¨ï¼Œæœ€å¯é  |
| **Puppeteer** | ğŸŸ¡ ä¸­ç­‰ | ğŸ’° ä¸­ç­‰ | â­â­â­â­ | Node.js é¡¹ç›® |
| **API é€†å‘å·¥ç¨‹** | ğŸ”´ å›°éš¾ | ğŸ’° ä½ | â­â­ | ç‰¹å®šç½‘ç«™ |
| **ç¬¬ä¸‰æ–¹æœåŠ¡** | ğŸŸ¢ ç®€å• | ğŸ’°ğŸ’° é«˜ | â­â­â­ | å¿«é€Ÿå®ç° |
| **ChatGPT API** | ğŸŸ¢ ç®€å• | ğŸ’°ğŸ’° é«˜ | â­â­â­â­â­ | æœ€ç®€å• |

---

## æ–¹æ¡ˆ 1ï¼šPlaywrightï¼ˆPythonï¼‰â­â­â­â­â­ æ¨è

### ä»€ä¹ˆæ˜¯ Playwrightï¼Ÿ

Playwright æ˜¯å¾®è½¯å¼€å‘çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·ï¼Œå¯ä»¥ï¼š
- è¿è¡ŒçœŸå®çš„ Chrome/Firefox æµè§ˆå™¨
- æ‰§è¡Œ JavaScript
- ç­‰å¾…åŠ¨æ€å†…å®¹åŠ è½½
- æˆªå›¾ã€ç‚¹å‡»ã€æ»šåŠ¨ç­‰æ“ä½œ

### å®‰è£…

```bash
pip install playwright
playwright install chromium
```

### ä»£ç ç¤ºä¾‹ï¼šæŠ“å– Facebook è¯„è®º

```python
from playwright.async_api import async_playwright
import asyncio

async def scrape_facebook_comments(url: str):
    """
    ä½¿ç”¨ Playwright æŠ“å– Facebook è¯„è®º
    """
    async with async_playwright() as p:
        # 1. å¯åŠ¨æµè§ˆå™¨ï¼ˆheadless=True è¡¨ç¤ºåå°è¿è¡Œï¼‰
        browser = await p.chromium.launch(headless=True)

        # 2. åˆ›å»ºæ–°é¡µé¢
        page = await browser.new_page()

        # 3. è®¿é—® Facebook URL
        await page.goto(url, wait_until='networkidle')

        # 4. ç­‰å¾…è¯„è®ºåŠ è½½ï¼ˆå¯èƒ½éœ€è¦æ»šåŠ¨ï¼‰
        await page.wait_for_selector('[data-testid="UFI2Comment/root_depth_0"]', timeout=10000)

        # 5. æ»šåŠ¨åŠ è½½æ›´å¤šè¯„è®º
        for _ in range(3):  # æ»šåŠ¨ 3 æ¬¡
            await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
            await asyncio.sleep(2)  # ç­‰å¾…åŠ è½½

        # 6. æå–è¯„è®ºå†…å®¹
        comments = await page.evaluate('''
            () => {
                const commentElements = document.querySelectorAll('[data-testid="UFI2Comment/root_depth_0"]');
                return Array.from(commentElements).map(el => ({
                    text: el.innerText,
                    author: el.querySelector('[data-testid="UFI2CommentsCount/sentenceWithCommentCount"]')?.innerText || ''
                }));
            }
        ''')

        # 7. å…³é—­æµè§ˆå™¨
        await browser.close()

        return comments

# ä½¿ç”¨
url = "https://www.facebook.com/ColumbiaAsiaHospitalPetalingJaya/posts/1298529398952280"
comments = await scrape_facebook_comments(url)

for comment in comments:
    print(f"ä½œè€…: {comment['author']}")
    print(f"å†…å®¹: {comment['text']}")
    print()
```

### ä¼˜ç‚¹

- âœ… å¯ä»¥æŠ“å–ä»»ä½•åŠ¨æ€å†…å®¹
- âœ… æ‰§è¡Œ JavaScriptï¼Œçœ‹åˆ°çœŸå®å†…å®¹
- âœ… å¯ä»¥æ¨¡æ‹Ÿæ»šåŠ¨ã€ç‚¹å‡»ç­‰æ“ä½œ
- âœ… æ”¯æŒ Chrome/Firefox/Safari

### ç¼ºç‚¹

- âŒ éœ€è¦è¿è¡Œæµè§ˆå™¨ï¼ˆå ç”¨èµ„æºï¼‰
- âŒ é€Ÿåº¦è¾ƒæ…¢ï¼ˆæ¯æ¬¡ 5-10 ç§’ï¼‰
- âŒ Facebook å¯èƒ½æ£€æµ‹å¹¶é˜»æ­¢ï¼ˆéœ€è¦å¤„ç†ï¼‰

### æˆæœ¬

```
Railway æœåŠ¡å™¨ï¼ˆéœ€è¦æ›´å¤šèµ„æºï¼‰:
- Hobby: $10/æœˆï¼ˆå¯èƒ½ä¸å¤Ÿï¼‰
- Pro: $20/æœˆï¼ˆæ¨èï¼‰

æ¯æ¬¡æŠ“å–æ—¶é—´ï¼š5-10 ç§’
å¹¶å‘é™åˆ¶ï¼šå»ºè®® 2-3 ä¸ªæµè§ˆå™¨å®ä¾‹
```

---

## æ–¹æ¡ˆ 2ï¼šSeleniumï¼ˆPythonï¼‰â­â­â­â­

### ä»€ä¹ˆæ˜¯ Seleniumï¼Ÿ

Selenium æ˜¯è€ç‰Œçš„æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·ï¼ŒåŠŸèƒ½ç±»ä¼¼ Playwrightã€‚

### å®‰è£…

```bash
pip install selenium
# è¿˜éœ€è¦ä¸‹è½½ ChromeDriver
```

### ä»£ç ç¤ºä¾‹

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

def scrape_with_selenium(url: str):
    """
    ä½¿ç”¨ Selenium æŠ“å– Facebook è¯„è®º
    """
    # 1. é…ç½®æµè§ˆå™¨é€‰é¡¹
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')  # åå°è¿è¡Œ
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    # 2. å¯åŠ¨æµè§ˆå™¨
    driver = webdriver.Chrome(options=options)

    try:
        # 3. è®¿é—®é¡µé¢
        driver.get(url)

        # 4. ç­‰å¾…è¯„è®ºåŠ è½½
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '[role="article"]'))
        )

        # 5. æ»šåŠ¨åŠ è½½æ›´å¤š
        for _ in range(3):
            driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')
            time.sleep(2)

        # 6. æå–è¯„è®º
        comment_elements = driver.find_elements(By.CSS_SELECTOR, '[role="article"]')
        comments = []

        for el in comment_elements:
            text = el.text
            if text:
                comments.append({'text': text})

        return comments

    finally:
        # 7. å…³é—­æµè§ˆå™¨
        driver.quit()

# ä½¿ç”¨
url = "https://www.facebook.com/..."
comments = scrape_with_selenium(url)
```

### Playwright vs Selenium

| ç‰¹æ€§ | Playwright | Selenium |
|------|-----------|----------|
| é€Ÿåº¦ | â­â­â­â­â­ æ›´å¿« | â­â­â­ è¾ƒæ…¢ |
| API è®¾è®¡ | â­â­â­â­â­ ç°ä»£ | â­â­â­ ä¼ ç»Ÿ |
| å¼‚æ­¥æ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒ | âŒ éœ€è¦é¢å¤–é…ç½® |
| å®‰è£…å¤æ‚åº¦ | â­â­â­â­â­ ç®€å• | â­â­â­ éœ€è¦ driver |

**æ¨è**ï¼šç”¨ Playwrightï¼ˆæ›´ç°ä»£ã€æ›´å¿«ï¼‰

---

## æ–¹æ¡ˆ 3ï¼šAPI é€†å‘å·¥ç¨‹ â­â­

### åŸç†

å¾ˆå¤šç½‘ç«™çš„åŠ¨æ€å†…å®¹é€šè¿‡ API åŠ è½½ã€‚å¦‚æœèƒ½æ‰¾åˆ° API ç«¯ç‚¹ï¼Œç›´æ¥è°ƒç”¨ API æ›´å¿«ã€‚

### æ­¥éª¤

```
1. æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰
2. è®¿é—® Facebook å¸–å­
3. æŸ¥çœ‹ Network æ ‡ç­¾
4. æ‰¾åˆ°è¯„è®ºçš„ API è¯·æ±‚ï¼ˆä¾‹å¦‚ /api/graphqlï¼‰
5. åˆ†æè¯·æ±‚å‚æ•°å’Œå“åº”æ ¼å¼
6. ç”¨ Python æ¨¡æ‹Ÿç›¸åŒçš„è¯·æ±‚
```

### ç¤ºä¾‹ï¼ˆå‡è®¾æ‰¾åˆ°äº† APIï¼‰

```python
import httpx

async def fetch_facebook_comments_api(post_id: str):
    """
    ç›´æ¥è°ƒç”¨ Facebook APIï¼ˆéœ€è¦é€†å‘æ‰¾åˆ°ç«¯ç‚¹ï¼‰
    """
    url = "https://www.facebook.com/api/graphql"

    # éœ€è¦çš„å‚æ•°ï¼ˆé€šè¿‡æµè§ˆå™¨æŠ“åŒ…è·å¾—ï¼‰
    params = {
        "doc_id": "123456789",  # GraphQL æŸ¥è¯¢ ID
        "variables": {
            "postID": post_id,
            "count": 50
        }
    }

    headers = {
        "User-Agent": "Mozilla/5.0...",
        "Cookie": "session_token=...",  # å¯èƒ½éœ€è¦ç™»å½•
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(url, json=params, headers=headers)
        data = response.json()

        # è§£æ API å“åº”
        comments = data['data']['node']['comments']['edges']
        return comments
```

### ä¼˜ç‚¹

- âœ… é€Ÿåº¦å¿«ï¼ˆç›´æ¥ API è°ƒç”¨ï¼‰
- âœ… èµ„æºå ç”¨å°‘ï¼ˆä¸éœ€è¦æµè§ˆå™¨ï¼‰
- âœ… å¯ä»¥æ‰¹é‡è·å–

### ç¼ºç‚¹

- âŒ éœ€è¦é€†å‘å·¥ç¨‹ï¼ˆå¾ˆéš¾ï¼‰
- âŒ API å¯èƒ½éšæ—¶å˜åŒ–
- âŒ å¯èƒ½éœ€è¦ç™»å½•å‡­è¯
- âŒ è¿åæœåŠ¡æ¡æ¬¾é£é™©

---

## æ–¹æ¡ˆ 4ï¼šç¬¬ä¸‰æ–¹çˆ¬è™«æœåŠ¡ â­â­â­

### æœåŠ¡é€‰é¡¹

#### Apifyï¼ˆæ¨èï¼‰

- ä¸“ä¸šçš„çˆ¬è™«å¹³å°
- æœ‰ç°æˆçš„ Facebook Scraper
- å®šä»·ï¼š$49/æœˆèµ·

```python
from apify_client import ApifyClient

client = ApifyClient('your_api_token')

# è¿è¡Œ Facebook Comments Scraper
run = client.actor("apify/facebook-comments-scraper").call(
    run_input={
        "startUrls": [
            "https://www.facebook.com/ColumbiaAsiaHospitalPetalingJaya/posts/1298529398952280"
        ],
        "maxComments": 100
    }
)

# è·å–ç»“æœ
comments = client.dataset(run["defaultDatasetId"]).list_items().items
```

#### Bright Dataï¼ˆåŸ Luminatiï¼‰

- ä¼ä¸šçº§çˆ¬è™«æœåŠ¡
- æä¾›æµè§ˆå™¨ API
- å®šä»·ï¼š$500/æœˆèµ·ï¼ˆè´µï¼‰

#### ScrapingBee

- æµè§ˆå™¨è‡ªåŠ¨åŒ– API
- å¤„ç† JavaScript æ¸²æŸ“
- å®šä»·ï¼š$49/æœˆï¼ˆ1000 æ¬¡è¯·æ±‚ï¼‰

```python
import requests

response = requests.get(
    url='https://app.scrapingbee.com/api/v1/',
    params={
        'api_key': 'YOUR_API_KEY',
        'url': 'https://www.facebook.com/...',
        'render_js': 'true',  # æ‰§è¡Œ JavaScript
        'wait': 5000  # ç­‰å¾… 5 ç§’
    }
)

html = response.text
# ç”¨ BeautifulSoup è§£æ
```

### ä¼˜ç‚¹

- âœ… å¼€ç®±å³ç”¨ï¼Œä¸éœ€è¦ç»´æŠ¤åŸºç¡€è®¾æ–½
- âœ… å¤„ç†åçˆ¬æªæ–½ï¼ˆä»£ç†ã€User-Agent è½®æ¢ï¼‰
- âœ… å¯é æ€§é«˜

### ç¼ºç‚¹

- âŒ æˆæœ¬é«˜ï¼ˆ$49-500/æœˆï¼‰
- âŒ ä¾èµ–ç¬¬ä¸‰æ–¹æœåŠ¡

---

## æ–¹æ¡ˆ 5ï¼šChatGPT APIï¼ˆæœ€ç®€å•ï¼‰â­â­â­â­â­

### åŸç†

OpenAI çš„ ChatGPT å·²ç»å†…ç½®äº† Web Browser Toolï¼Œå¯ä»¥ç›´æ¥è®¿é—®åŠ¨æ€ç½‘é¡µã€‚

### ä»£ç ç¤ºä¾‹

```python
from openai import AsyncOpenAI

async def search_with_chatgpt(doctor_name: str, facebook_url: str = None):
    """
    ä½¿ç”¨ ChatGPT æœç´¢åŒ»ç”Ÿè¯„ä»·ï¼ˆåŒ…æ‹¬ Facebook è¯„è®ºï¼‰
    """
    client = AsyncOpenAI(api_key='your_api_key')

    if facebook_url:
        # æŒ‡å®š URL
        prompt = f"è®¿é—®è¿™ä¸ª Facebook å¸–å­å¹¶æå–å…³äº {doctor_name} çš„æ‚£è€…è¯„ä»·ï¼š{facebook_url}"
    else:
        # è®© ChatGPT è‡ªå·±æœç´¢
        prompt = f"æœç´¢ {doctor_name} åœ¨é©¬æ¥è¥¿äºšçš„æ‚£è€…è¯„ä»·ï¼ŒåŒ…æ‹¬ Facebookã€Google Mapsã€è®ºå›"

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{
            "role": "user",
            "content": prompt
        }]
        # ChatGPT ä¼šè‡ªåŠ¨ä½¿ç”¨ web search + web browser
    )

    return response.choices[0].message.content

# ä½¿ç”¨
result = await search_with_chatgpt(
    doctor_name="Dr. Paul Ngalap Ayu",
    facebook_url="https://www.facebook.com/ColumbiaAsiaHospitalPetalingJaya/posts/1298529398952280"
)

print(result)
# ChatGPT ä¼šè¿”å›ï¼š
# "åœ¨è¿™ä¸ª Facebook å¸–å­ä¸­ï¼Œæ‰¾åˆ°äº† 3 æ¡å…³äº Dr. Paul çš„è¯„ä»·ï¼š
# 1. æ‚£è€…Aè¯´ï¼šDr. Paul å¾ˆä¸“ä¸š...
# 2. æ‚£è€…Bè¯´ï¼šDr. Paul å¸®æˆ‘æ²»å¥½äº†...
# 3. ..."
```

### ä¼˜ç‚¹

- âœ…âœ…âœ… æœ€ç®€å•ï¼ˆå‡ è¡Œä»£ç ï¼‰
- âœ… ä¸éœ€è¦ç»´æŠ¤æµè§ˆå™¨åŸºç¡€è®¾æ–½
- âœ… å¯é æ€§é«˜ï¼ˆOpenAI ç»´æŠ¤ï¼‰
- âœ… å¯ä»¥æœç´¢ + æŠ“å– + åˆ†æä¸€æ­¥å®Œæˆ

### ç¼ºç‚¹

- âŒ æˆæœ¬è¾ƒé«˜ï¼ˆGPT-4o: ~$0.04/æ¬¡ï¼‰
- âŒ ä¾èµ– OpenAI

### æˆæœ¬

```
æ¯æ¬¡æœç´¢ï¼š
- Input: ~5,000 tokens
- Output: ~3,000 tokens
- æˆæœ¬ï¼š$0.0125 + $0.03 = $0.0425

æœˆæˆæœ¬ï¼ˆ1,500æ¬¡ï¼‰ï¼š
1,500 Ã— $0.0425 = $63.75/æœˆ
```

---

## Facebook ç‰¹æ®ŠæŒ‘æˆ˜

### æŒ‘æˆ˜ 1ï¼šç™»å½•å¢™

å¾ˆå¤š Facebook å†…å®¹éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# Playwright ç™»å½• Facebook
async def login_facebook(page):
    await page.goto('https://www.facebook.com/login')
    await page.fill('input[name="email"]', 'your_email@example.com')
    await page.fill('input[name="pass"]', 'your_password')
    await page.click('button[name="login"]')
    await page.wait_for_url('https://www.facebook.com/', timeout=10000)

    # ä¿å­˜ cookies
    cookies = await page.context.cookies()
    return cookies
```

**é£é™©**ï¼š
- âŒ è¿å Facebook æœåŠ¡æ¡æ¬¾
- âŒ è´¦å·å¯èƒ½è¢«å°ç¦

### æŒ‘æˆ˜ 2ï¼šåçˆ¬è™«æ£€æµ‹

Facebook ä¼šæ£€æµ‹å¹¶é˜»æ­¢çˆ¬è™«ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# ä½¿ç”¨ Playwright çš„éšèº«æ¨¡å¼
async def scrape_with_stealth(url):
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox'
            ]
        )

        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) ...',
            viewport={'width': 1920, 'height': 1080},
            locale='en-US'
        )

        page = await context.new_page()

        # åˆ é™¤ webdriver æ ‡è®°
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => false
            });
        """)

        await page.goto(url)
        # ... æŠ“å–å†…å®¹
```

### æŒ‘æˆ˜ 3ï¼šåŠ¨æ€é€‰æ‹©å™¨

Facebook çš„ HTML ç»“æ„ç»å¸¸å˜åŒ–ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# ä½¿ç”¨å¤šä¸ªå¤‡é€‰é€‰æ‹©å™¨
selectors = [
    '[data-testid="UFI2Comment/root_depth_0"]',  # é€‰æ‹©å™¨ 1
    '[role="article"]',  # é€‰æ‹©å™¨ 2
    '.comment-content',  # é€‰æ‹©å™¨ 3
]

for selector in selectors:
    try:
        elements = await page.query_selector_all(selector)
        if elements:
            break
    except:
        continue
```

---

## å®Œæ•´å®ç°ç¤ºä¾‹

### é›†æˆåˆ°é¡¹ç›®ä¸­

```python
# src/search/facebook_scraper.py

from playwright.async_api import async_playwright
import asyncio
import logging

logger = logging.getLogger(__name__)

class FacebookScraper:
    """ä½¿ç”¨ Playwright æŠ“å– Facebook è¯„è®º"""

    def __init__(self):
        self.enabled = True

    async def scrape_post_comments(self, url: str, doctor_name: str, max_comments: int = 50):
        """
        æŠ“å– Facebook å¸–å­çš„è¯„è®º

        Args:
            url: Facebook å¸–å­ URL
            doctor_name: åŒ»ç”Ÿåå­—ï¼ˆç”¨äºè¿‡æ»¤ç›¸å…³è¯„è®ºï¼‰
            max_comments: æœ€å¤šæŠ“å–è¯„è®ºæ•°

        Returns:
            List of comments
        """
        try:
            async with async_playwright() as p:
                # å¯åŠ¨æµè§ˆå™¨
                browser = await p.chromium.launch(headless=True)
                page = await browser.new_page()

                # è®¿é—®é¡µé¢
                logger.info(f"æ­£åœ¨è®¿é—® Facebook: {url}")
                await page.goto(url, wait_until='networkidle', timeout=30000)

                # ç­‰å¾…å†…å®¹åŠ è½½
                await asyncio.sleep(3)

                # æ»šåŠ¨åŠ è½½æ›´å¤šè¯„è®º
                for i in range(3):
                    await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                    await asyncio.sleep(2)
                    logger.info(f"æ»šåŠ¨åŠ è½½ {i+1}/3")

                # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                content = await page.evaluate('() => document.body.innerText')

                await browser.close()

                # ç”¨ç®€å•çš„æ–‡æœ¬åˆ†ææå–ç›¸å…³è¯„è®º
                comments = self._extract_relevant_comments(content, doctor_name)

                logger.info(f"æ‰¾åˆ° {len(comments)} æ¡ç›¸å…³è¯„è®º")
                return comments[:max_comments]

        except Exception as e:
            logger.error(f"Facebook æŠ“å–å¤±è´¥: {e}")
            return []

    def _extract_relevant_comments(self, content: str, doctor_name: str):
        """ç®€å•çš„æ–‡æœ¬è¿‡æ»¤"""
        lines = content.split('\n')
        comments = []

        for line in lines:
            # å¦‚æœè¿™è¡Œæåˆ°åŒ»ç”Ÿåå­—
            if doctor_name.lower() in line.lower():
                # å¹¶ä¸”é•¿åº¦åˆç†ï¼ˆå¯èƒ½æ˜¯è¯„è®ºï¼‰
                if 20 < len(line) < 500:
                    comments.append({
                        'text': line,
                        'source': 'facebook'
                    })

        return comments

# ä½¿ç”¨
facebook_scraper = FacebookScraper()
```

### é›†æˆåˆ°æœç´¢èšåˆå™¨

```python
# src/search/aggregator.py

async def search_doctor_reviews(doctor_name: str):
    """å®Œæ•´çš„æœç´¢æµç¨‹"""

    # 1. Outscraper - Google Mapsï¼ˆå…³é”®è¯æœç´¢ï¼‰
    logger.info("ğŸ—ºï¸ æœç´¢ Google Maps è¯„ä»·...")
    google_maps_reviews = await outscraper_client.google_maps_reviews(
        query=f"{doctor_name} Malaysia",
        reviews_query=doctor_name,
        limit=20
    )

    # 2. Google Custom Search - è®ºå›
    logger.info("ğŸ“‹ æœç´¢è®ºå›è¯„ä»·...")
    forum_urls = await google_searcher.search_doctor_reviews(
        doctor_name=doctor_name,
        location="Malaysia"
    )

    # 3. Facebookï¼ˆå¯é€‰ï¼Œå¦‚æœç”¨æˆ·æä¾›äº† URLï¼‰
    facebook_reviews = []
    if known_facebook_url:
        logger.info("ğŸ“˜ æŠ“å– Facebook è¯„ä»·...")
        facebook_reviews = await facebook_scraper.scrape_post_comments(
            url=known_facebook_url,
            doctor_name=doctor_name
        )

    # 4. åˆå¹¶æ‰€æœ‰ç»“æœ
    return {
        "google_maps": google_maps_reviews,
        "forums": forum_urls,
        "facebook": facebook_reviews,
        "total_count": len(google_maps_reviews) + len(facebook_reviews)
    }
```

---

## æˆæœ¬å¯¹æ¯”ï¼ˆ30ç”¨æˆ·ï¼Œ1,500æ¬¡/æœˆï¼‰

| æ–¹æ¡ˆ | æœˆæˆæœ¬ | è¯´æ˜ |
|------|--------|------|
| Outscraper å…³é”®è¯æœç´¢ | $45 | Google Maps only |
| + Playwright (è‡ªå»º) | $45 + $20 = $65 | éœ€è¦ Pro æœåŠ¡å™¨ |
| + Apify | $45 + $49 = $94 | ç¬¬ä¸‰æ–¹æœåŠ¡ |
| + ChatGPT API | $45 + $64 = $109 | æœ€ç®€å• |

---

## æœ€ç»ˆå»ºè®®

### å¦‚æœè¦å®ç° Facebook è¯„è®ºæŠ“å–

**æ¨èæ–¹æ¡ˆï¼šChatGPT API** â­â­â­â­â­

ç†ç”±ï¼š
1. âœ… æœ€ç®€å•ï¼ˆå‡ è¡Œä»£ç ï¼‰
2. âœ… ä¸éœ€è¦ç»´æŠ¤æµè§ˆå™¨åŸºç¡€è®¾æ–½
3. âœ… OpenAI å¤„ç†æ‰€æœ‰åçˆ¬æªæ–½
4. âœ… æˆæœ¬å¯æ¥å—ï¼ˆ$109/æœˆ = $3.63/ç”¨æˆ·/æœˆï¼‰

**å¦‚æœé¢„ç®—ç´§å¼ ï¼šPlaywright è‡ªå»º**

ç†ç”±ï¼š
1. âœ… æˆæœ¬è¾ƒä½ï¼ˆ$65/æœˆï¼‰
2. âš ï¸ éœ€è¦å¤„ç†åçˆ¬æªæ–½
3. âš ï¸ éœ€è¦ç»´æŠ¤ä»£ç ï¼ˆFacebook ç»“æ„å˜åŒ–ï¼‰

### ä½†æœ€é‡è¦çš„é—®é¢˜

**æ˜¯å¦çœŸçš„éœ€è¦ Facebook è¯„è®ºï¼Ÿ**

- Google Maps è¯„ä»·å·²ç»å¾ˆå…¨é¢ï¼ˆé€šè¿‡ Outscraper å…³é”®è¯æœç´¢ï¼‰
- Facebook è¯„è®ºæ•°é‡è¾ƒå°‘
- æŠ€æœ¯å¤æ‚åº¦å’Œæˆæœ¬æ˜¾è‘—å¢åŠ 

**å»ºè®®**ï¼š
1. å…ˆåªåš Google Mapsï¼ˆ$45/æœˆï¼‰
2. æµ‹è¯•ç”¨æˆ·åé¦ˆ
3. å¦‚æœç”¨æˆ·å¼ºçƒˆéœ€è¦ Facebook â†’ å†åŠ ä¸Š ChatGPT API

---

**æ–‡æ¡£åˆ›å»ºæ—¶é—´**ï¼š2025-10-30
**ç»“è®º**ï¼šåŠ¨æ€é¡µé¢æŠ“å–æŠ€æœ¯å¯è¡Œï¼Œä½†å»ºè®®ä» Google Maps å¼€å§‹ï¼ŒæŒ‰éœ€æ·»åŠ  Facebook
